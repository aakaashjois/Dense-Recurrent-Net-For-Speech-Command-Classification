{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2nfRWRp0Niz0"
   },
   "source": [
    "# Make training, testing and validation datasets\n",
    "\n",
    "- Split entire dataset into training, testing and validation\n",
    "- .txt files (provided by Kaggle) contain filenames of testing and validation audio files\n",
    "- XOR all filenames with testing and validation filenames to create a set of training filenames\n",
    "- Create Mel-power spectrograms for each audio file\n",
    "- Save all as `.npy` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vbc47rkoK9GT"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directory structure**:<br>\n",
    "data:<br>\n",
    "| - testing_list.txt<br>\n",
    "| - validation_list.txt<br>\n",
    "| audio<br>\n",
    ". . | - .<br>\n",
    ". . | - ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uiMrNJEb73CL"
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATA = os.path.join(os.getcwd(), 'data')\n",
    "PATH_TO_AUDIO = os.path.join(PATH_TO_DATA, 'audio')\n",
    "SAMPLING_RATE = 16000\n",
    "\n",
    "# Removing leading '/data/audio/' from all paths\n",
    "all_data_paths = glob.glob(os.path.join(PATH_TO_AUDIO, '*', '*'))\n",
    "all_data_paths = np.vectorize(str.replace)(all_data_paths, os.path.join(PATH_TO_AUDIO, ''), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LCp92uBELz7x"
   },
   "outputs": [],
   "source": [
    "# Create a lambda function that helps in vectorizing the string replace function\n",
    "split_join = lambda x: os.path.join(*str.split(x, '/'))\n",
    "\n",
    "with open(os.path.join(PATH_TO_DATA,'testing_list.txt')) as f:\n",
    "    test_data_paths = f.readlines()\n",
    "test_data_paths = np.vectorize(str.replace)(test_data_paths, '\\n', '')\n",
    "test_data_paths = np.vectorize(split_join)(test_data_paths)\n",
    "\n",
    "with open(os.path.join(PATH_TO_DATA, 'validation_list.txt')) as f:\n",
    "    validation_data_paths = f.readlines()\n",
    "validation_data_paths = np.vectorize(str.replace)(validation_data_paths, '\\n', '')\n",
    "validation_data_paths = np.vectorize(split_join)(validation_data_paths)\n",
    "\n",
    "train_data_paths = list(set(all_data_paths) ^ set(validation_data_paths) ^ set(test_data_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio_file(audio_file_path):\n",
    "    # Read audio file\n",
    "    # If audio file is shroter than 16000 samples, zero-pad keeping the audio in the center\n",
    "    # If audio file is longer than 16000 samples, center crop to 16000 samples\n",
    "    audio_file = librosa.load(os.path.join(PATH_TO_AUDIO, audio_file_path))[0]\n",
    "    if len(audio_file) < SAMPLING_RATE:\n",
    "        if len(audio_file) % 2 == 1:\n",
    "            audio_file = np.append(audio_file, [0])\n",
    "        pad_width = (SAMPLING_RATE - len(audio_file)) // 2\n",
    "        audio_file = np.pad(audio_file, pad_width=pad_width, mode='constant')\n",
    "        audio_file = audio_file[0: SAMPLING_RATE]\n",
    "    elif len(audio_file) > SAMPLING_RATE:\n",
    "        length_to_truncate = (len(audio_file) - SAMPLING_RATE) // 2\n",
    "        audio_file = audio_file[length_to_truncate : SAMPLING_RATE + length_to_truncate]\n",
    "    return audio_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_power_spectrogram(audio_file):\n",
    "    return librosa.power_to_db(librosa.feature.melspectrogram(audio_file, \n",
    "                                                              sr=SAMPLING_RATE, \n",
    "                                                              n_fft=1024, \n",
    "                                                              hop_length=256, \n",
    "                                                              fmax=3000), \n",
    "                               ref=np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and save training, testing and validation datasets as `.npy` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_split_spectrogram():\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    validation_data = []\n",
    "    validation_labels = []\n",
    "    test_data = []\n",
    "    test_labels = []\n",
    "    \n",
    "    print('Creating train data')\n",
    "    for path in train_data_paths:\n",
    "        train_data.append(get_mel_power_spectrogram(read_audio_file(path)))\n",
    "        train_labels.append(path.split(os.path.sep)[0])\n",
    "        \n",
    "    print('Creating validation data')\n",
    "    for path in validation_data_paths:\n",
    "        validation_data.append(get_mel_power_spectrogram(read_audio_file(path)))\n",
    "        validation_labels.append(path.split(os.path.sep)[0])\n",
    "    \n",
    "    print('Creating test data')\n",
    "    for path in test_data_paths:\n",
    "        test_data.append(get_mel_power_spectrogram(read_audio_file(path)))\n",
    "        test_labels.append(path.split(os.path.sep)[0])\n",
    "             \n",
    "    train_data = (np.array(train_data) - np.mean(train_data)) / np.std(train_data)\n",
    "    validation_data = (np.array(validation_data) - np.mean(validation_data)) / np.std(validation_data)\n",
    "    test_data = (np.array(test_data) - np.mean(test_data)) / np.std(test_data)\n",
    "    np.save(os.path.join(PATH_TO_DATA, 'train_data'), train_data)\n",
    "    np.save(os.path.join(PATH_TO_DATA, 'train_labels'), train_labels)\n",
    "    np.save(os.path.join(PATH_TO_DATA, 'validation_data'), validation_data)\n",
    "    np.save(os.path.join(PATH_TO_DATA, 'validation_labels'), validation_labels)\n",
    "    np.save(os.path.join(PATH_TO_DATA, 'test_data'), test_data)\n",
    "    np.save(os.path.join(PATH_TO_DATA, 'test_labels'), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_data_split_spectrogram()\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "SCURRNN.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
